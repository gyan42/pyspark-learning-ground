{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "technical-secret",
   "metadata": {},
   "source": [
    "# Partition\n",
    "\n",
    "https://kontext.tech/column/spark/296/data-partitioning-in-spark-pyspark-in-depth-walkthrough  \n",
    "https://kontext.tech/column/spark/299/data-partitioning-functions-in-spark-pyspark-explained  \n",
    "https://mungingdata.com/apache-spark/partitionby/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "found-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dependent-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_CORES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "convenient-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://IMCHLT276:7077\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.cores.max\", f\"{MAX_NUM_CORES}\") \\\n",
    "    .config(\"spark.local.dir\", \"/opt/tmp/spark-temp/\") \\\n",
    "    .appName(\"DataSkewness\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "detected-stroke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.142:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://IMCHLT276:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataSkewness</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f068ce5cf50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-grant",
   "metadata": {},
   "source": [
    "**Test how partition size affects the output file numbers**\n",
    "\n",
    "**Test 1** : Number of partition is equal to the cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abroad-earthquake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "| 15|\n",
      "| 16|\n",
      "| 17|\n",
      "| 18|\n",
      "| 19|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.range(100000)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eastern-championship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions() == MAX_NUM_CORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "subjective-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf /tmp/df_tes/\n",
    "df.write.parquet(\"/tmp/df_tes/\")\n",
    "!ls /tmp/df_tes/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-element",
   "metadata": {},
   "source": [
    "**Test 2** : Repartition will affect the number ouput files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "departmental-islam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.range(100000)\n",
    "df = df.repartition(20)\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "contemporary-impression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\n",
      "part-00000-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00001-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00002-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00003-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00004-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00005-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00006-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00007-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00008-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00009-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00010-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00011-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00012-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00013-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00014-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00015-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00016-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00017-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00018-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n",
      "part-00019-1876d46c-f683-4ebd-81a7-e99f246916a8-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "! rm -rf /tmp/df_tes/\n",
    "df.write.parquet(\"/tmp/df_tes/\")\n",
    "!ls /tmp/df_tes/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-guidance",
   "metadata": {},
   "source": [
    "**Test 3** : Repartition to 1 and see waht happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cognitive-pantyhose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.range(10000000)\n",
    "df = df.repartition(1)\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "representative-murder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 39M\n",
      "drwxrwxr-x  2 mageswarand mageswarand 4.0K Feb 18 13:26 .\n",
      "drwxrwxrwt 36 root        root        4.0K Feb 18 13:26 ..\n",
      "-rw-r--r--  1 mageswarand mageswarand    8 Feb 18 13:26 ._SUCCESS.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand 306K Feb 18 13:26 .part-00000-40d5a79d-70bf-4762-bddb-22a29d64db6e-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand    0 Feb 18 13:26 _SUCCESS\n",
      "-rw-r--r--  1 mageswarand mageswarand  39M Feb 18 13:26 part-00000-40d5a79d-70bf-4762-bddb-22a29d64db6e-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "! rm -rf /tmp/df_tes/\n",
    "df.write.parquet(\"/tmp/df_tes/\")\n",
    "!ls /tmp/df_tes/ -alh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-arnold",
   "metadata": {},
   "source": [
    "**Test 4** : coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bright-richmond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.range(100000)\n",
    "df = df.coalesce(1)\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "lesbian-frontier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS  part-00000-2b4e54a3-e11e-4a5a-b53d-96f0e42d9c51-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "! rm -rf /tmp/df_tes/\n",
    "df.write.parquet(\"/tmp/df_tes/\")\n",
    "!ls /tmp/df_tes/ -alh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-wesley",
   "metadata": {},
   "source": [
    "**Test 5** : Add a text column and repartition to 1 and see waht happens? Size on local disk doesn't matter. On HDFS this may change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "domestic-spoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chars to choose from 26884\n"
     ]
    }
   ],
   "source": [
    "import string, random\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "letters = string.ascii_lowercase\n",
    "letters_upper = string.ascii_uppercase\n",
    "\n",
    "for _i in range(0, 10):\n",
    "    letters += letters\n",
    "\n",
    "for _i in range(0, 10):\n",
    "    letters += letters_upper\n",
    "\n",
    "print(\"Number of chars to choose from\", len(letters))\n",
    "sample_string = random.sample(letters, 500)\n",
    "# print(\"sample_string\", ''.join(sample_string))\n",
    "\n",
    "def random_string(stringLength=200):\n",
    "    \"\"\"Generate a random string of fixed length \"\"\"\n",
    "    return ''.join(random.sample(letters, stringLength))\n",
    "\n",
    "random_string_udf = F.udf(random_string,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "flexible-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(1000000)\n",
    "df = df.withColumn(\"data\", random_string_udf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "motivated-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(1, F.col(\"data\"))\n",
    "df = df.select(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "architectural-depth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "weekly-packing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 4 µs, total: 10 µs\n",
      "Wall time: 18.1 µs\n",
      "total 197M\n",
      "drwxrwxr-x  2 mageswarand mageswarand 4.0K Feb 18 14:32 .\n",
      "drwxrwxrwt 36 root        root        4.0K Feb 18 14:32 ..\n",
      "-rw-r--r--  1 mageswarand mageswarand    8 Feb 18 14:32 ._SUCCESS.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand 1.6M Feb 18 14:32 .part-00000-90cd6cf3-8eb1-445d-a85e-c9a464f4a094-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand    0 Feb 18 14:32 _SUCCESS\n",
      "-rw-r--r--  1 mageswarand mageswarand 195M Feb 18 14:32 part-00000-90cd6cf3-8eb1-445d-a85e-c9a464f4a094-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "! rm -rf /tmp/df_tes/\n",
    "df.write.parquet(\"/tmp/df_tes/\")\n",
    "!ls /tmp/df_tes/ -alh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "southeast-neighbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|SPARK_PARTITION_ID()|  count|\n",
      "+--------------------+-------+\n",
      "|                   0|1000000|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import spark_partition_id\n",
    "\n",
    "df.groupBy(spark_partition_id()).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-amateur",
   "metadata": {},
   "source": [
    "**Test 6** : Read back the stored DF with 1 partition and see how many partitions are there? Equals to number of cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial-generic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"/tmp/df_tes/\")\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-employment",
   "metadata": {},
   "source": [
    "**Test 7** Store as many paritions and read it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "designing-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(1000000)\n",
    "df = df.withColumn(\"data\", random_string_udf())\n",
    "df = df.repartition(32, F.col(\"data\"))\n",
    "df = df.select(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "maritime-height",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 2 µs, total: 5 µs\n",
      "Wall time: 8.82 µs\n",
      "total 197M\n",
      "drwxrwxr-x  2 mageswarand mageswarand  12K Feb 18 15:38 .\n",
      "drwxrwxrwt 36 root        root        4.0K Feb 18 15:38 ..\n",
      "-rw-r--r--  1 mageswarand mageswarand    8 Feb 18 15:38 ._SUCCESS.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00000-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00001-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00002-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00003-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00004-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00005-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00006-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00007-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00008-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00009-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  50K Feb 18 15:38 .part-00010-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  50K Feb 18 15:38 .part-00011-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00012-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00013-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00014-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  50K Feb 18 15:38 .part-00015-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00016-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00017-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00018-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00019-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00020-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00021-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00022-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00023-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00024-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00025-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00026-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00027-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00028-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00029-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00030-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand  49K Feb 18 15:38 .part-00031-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet.crc\n",
      "-rw-r--r--  1 mageswarand mageswarand    0 Feb 18 15:38 _SUCCESS\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00000-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00001-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00002-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00003-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.2M Feb 18 15:38 part-00004-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00005-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00006-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00007-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.2M Feb 18 15:38 part-00008-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00009-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.2M Feb 18 15:38 part-00010-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.2M Feb 18 15:38 part-00011-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00012-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.2M Feb 18 15:38 part-00013-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00014-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.2M Feb 18 15:38 part-00015-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00016-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.2M Feb 18 15:38 part-00017-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00018-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00019-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00020-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00021-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00022-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00023-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00024-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.2M Feb 18 15:38 part-00025-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00026-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00027-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00028-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00029-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.1M Feb 18 15:38 part-00030-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n",
      "-rw-r--r--  1 mageswarand mageswarand 6.2M Feb 18 15:38 part-00031-87fc8316-4176-4e93-aa56-2b347163f81a-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "! rm -rf /tmp/df_tes/\n",
    "df.write.parquet(\"/tmp/df_tes/\")\n",
    "!ls /tmp/df_tes/ -alh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "extraordinary-blocking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"/tmp/df_tes/\")\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "optional-spending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|SPARK_PARTITION_ID()|count|\n",
      "+--------------------+-----+\n",
      "|                   1|94124|\n",
      "|                   6|93649|\n",
      "|                   3|93967|\n",
      "|                   5|93696|\n",
      "|                   9|93054|\n",
      "|                   4|93792|\n",
      "|                   8|93361|\n",
      "|                   7|93577|\n",
      "|                  10|61894|\n",
      "|                   2|94036|\n",
      "|                   0|94850|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(spark_partition_id()).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-collector",
   "metadata": {},
   "source": [
    "**Test 8** : Less number of records and more partitions? \n",
    "\n",
    "Spark will try to evenly distribute the data to each partitions. If the total partition number is greater than the actual record count (or RDD size), some partitions will be empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "harmful-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(10)\n",
    "df = df.withColumn(\"data\", random_string_udf())\n",
    "df = df.repartition(100, F.col(\"data\"))\n",
    "df = df.select(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "chief-greenhouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 3 µs, total: 9 µs\n",
      "Wall time: 16.2 µs\n",
      "_SUCCESS\n",
      "part-00000-f52592db-cf7e-40b5-b5e4-623bcb46f17e-c000.snappy.parquet\n",
      "part-00022-f52592db-cf7e-40b5-b5e4-623bcb46f17e-c000.snappy.parquet\n",
      "part-00024-f52592db-cf7e-40b5-b5e4-623bcb46f17e-c000.snappy.parquet\n",
      "part-00026-f52592db-cf7e-40b5-b5e4-623bcb46f17e-c000.snappy.parquet\n",
      "part-00032-f52592db-cf7e-40b5-b5e4-623bcb46f17e-c000.snappy.parquet\n",
      "part-00036-f52592db-cf7e-40b5-b5e4-623bcb46f17e-c000.snappy.parquet\n",
      "part-00037-f52592db-cf7e-40b5-b5e4-623bcb46f17e-c000.snappy.parquet\n",
      "part-00050-f52592db-cf7e-40b5-b5e4-623bcb46f17e-c000.snappy.parquet\n",
      "part-00058-f52592db-cf7e-40b5-b5e4-623bcb46f17e-c000.snappy.parquet\n",
      "part-00068-f52592db-cf7e-40b5-b5e4-623bcb46f17e-c000.snappy.parquet\n",
      "part-00070-f52592db-cf7e-40b5-b5e4-623bcb46f17e-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "! rm -rf /tmp/df_tes/\n",
    "df.write.parquet(\"/tmp/df_tes/\")\n",
    "!ls /tmp/df_tes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "invisible-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df.groupBy(spark_partition_id()).agg(F.count(\"data\").alias(\"id\")).orderBy(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "mighty-authority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|SPARK_PARTITION_ID()| id|\n",
      "+--------------------+---+\n",
      "|                  92|  1|\n",
      "|                  68|  1|\n",
      "|                  71|  1|\n",
      "|                  20|  1|\n",
      "|                  23|  1|\n",
      "|                  69|  1|\n",
      "|                  61|  1|\n",
      "|                  35|  1|\n",
      "|                   1|  1|\n",
      "|                  96|  1|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res.show(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "forty-chemical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-emerald",
   "metadata": {},
   "source": [
    "**Test 9** Default column repartition? Equals to 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "chronic-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(10000)\n",
    "df = df.withColumn(\"data\", random_string_udf())\n",
    "df = df.repartition(F.col(\"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bizarre-generation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 3 µs, total: 9 µs\n",
      "Wall time: 16 µs\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "! rm -rf /tmp/df_tes/\n",
    "df.write.parquet(\"/tmp/df_tes/\")\n",
    "!ls /tmp/df_tes/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "false-personality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(spark_partition_id()).count().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-motel",
   "metadata": {},
   "source": [
    "**Test 10** Muli column parition and write partition keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "orange-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "going-retreat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+\n",
      "|Country|      Date|Amount|\n",
      "+-------+----------+------+\n",
      "|     CN|2019-01-01|    10|\n",
      "|     AU|2019-01-01|    10|\n",
      "|     CN|2019-01-02|    11|\n",
      "|     AU|2019-01-02|    11|\n",
      "|     CN|2019-01-03|    12|\n",
      "|     AU|2019-01-03|    12|\n",
      "|     CN|2019-01-04|    13|\n",
      "|     AU|2019-01-04|    13|\n",
      "|     CN|2019-01-05|    14|\n",
      "|     AU|2019-01-05|    14|\n",
      "|     CN|2019-01-06|    15|\n",
      "|     AU|2019-01-06|    15|\n",
      "|     CN|2019-01-07|    16|\n",
      "|     AU|2019-01-07|    16|\n",
      "|     CN|2019-01-08|    17|\n",
      "|     AU|2019-01-08|    17|\n",
      "|     CN|2019-01-09|    18|\n",
      "|     AU|2019-01-09|    18|\n",
      "|     CN|2019-01-10|    19|\n",
      "|     AU|2019-01-10|    19|\n",
      "+-------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "start_date = date(2019, 1, 1)\n",
    "data = []\n",
    "for i in range(0, 50):\n",
    "    data.append({\"Country\": \"CN\", \"Date\": start_date +\n",
    "                 timedelta(days=i), \"Amount\": 10+i})\n",
    "    data.append({\"Country\": \"AU\", \"Date\": start_date +\n",
    "                 timedelta(days=i), \"Amount\": 10+i})\n",
    "\n",
    "schema = StructType([StructField('Country', StringType(), nullable=False),\n",
    "                     StructField('Date', DateType(), nullable=False),\n",
    "                     StructField('Amount', IntegerType(), nullable=False)])\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.show()\n",
    "print(df.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "happy-albert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "+-------+----------+------+----+-----+---+\n",
      "|Country|      Date|Amount|Year|Month|Day|\n",
      "+-------+----------+------+----+-----+---+\n",
      "|     AU|2019-01-21|    30|2019|    1| 21|\n",
      "|     CN|2019-01-29|    38|2019|    1| 29|\n",
      "|     AU|2019-01-19|    28|2019|    1| 19|\n",
      "|     AU|2019-02-07|    47|2019|    2|  7|\n",
      "|     AU|2019-02-02|    42|2019|    2|  2|\n",
      "|     AU|2019-02-05|    45|2019|    2|  5|\n",
      "|     AU|2019-02-08|    48|2019|    2|  8|\n",
      "|     CN|2019-01-27|    36|2019|    1| 27|\n",
      "|     CN|2019-01-21|    30|2019|    1| 21|\n",
      "|     CN|2019-01-25|    34|2019|    1| 25|\n",
      "|     AU|2019-01-11|    20|2019|    1| 11|\n",
      "|     CN|2019-02-06|    46|2019|    2|  6|\n",
      "|     CN|2019-02-19|    59|2019|    2| 19|\n",
      "|     CN|2019-01-19|    28|2019|    1| 19|\n",
      "|     AU|2019-02-03|    43|2019|    2|  3|\n",
      "|     AU|2019-02-09|    49|2019|    2|  9|\n",
      "|     CN|2019-01-14|    23|2019|    1| 14|\n",
      "|     AU|2019-01-16|    25|2019|    1| 16|\n",
      "|     CN|2019-02-16|    56|2019|    2| 16|\n",
      "|     AU|2019-01-10|    19|2019|    1| 10|\n",
      "+-------+----------+------+----+-----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"Year\", F.year(\"Date\")).withColumn(\"Month\", F.month(\"Date\")).withColumn(\"Day\", F.dayofmonth(\"Date\"))\n",
    "df = df.repartition(\"Year\", \"Month\", \"Day\", \"Country\")\n",
    "print(df.rdd.getNumPartitions())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "incredible-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.partitionBy(\"Year\", \"Month\", \"Day\", \"Country\").mode(\"overwrite\").csv(\"/tmp/df_tes/\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dental-alignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/tmp/df_tes/\u001b[00m\n",
      "├── \u001b[01;34mYear=2019\u001b[00m\n",
      "│   ├── \u001b[01;34mMonth=1\u001b[00m\n",
      "│   │   ├── \u001b[01;34mDay=1\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00151-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00172-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=10\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00037-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00112-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=11\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00026-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00111-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=12\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00060-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00060-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=13\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00039-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00150-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=14\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00170-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00033-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=15\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00104-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00138-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=16\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00033-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00106-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=17\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00135-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00173-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=18\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00147-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00173-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=19\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00017-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00027-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=2\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00046-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00104-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=20\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00125-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00180-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=21\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00000-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00025-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=22\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00041-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00081-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=23\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00078-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00125-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=24\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00132-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00072-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=25\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00076-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00026-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=26\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00119-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00161-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=27\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00114-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00024-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=28\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00157-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00052-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=29\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00038-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00005-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=3\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00046-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00192-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=30\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00175-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00071-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=31\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00084-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00068-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=4\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00115-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00099-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=5\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00067-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00110-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=6\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00066-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00132-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=7\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00096-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00167-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   ├── \u001b[01;34mDay=8\u001b[00m\n",
      "│   │   │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │   │   │   └── part-00151-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │   │       └── part-00082-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │   └── \u001b[01;34mDay=9\u001b[00m\n",
      "│   │       ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│   │       │   └── part-00174-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   │       └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│   │           └── part-00129-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│   └── \u001b[01;34mMonth=2\u001b[00m\n",
      "│       ├── \u001b[01;34mDay=1\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00103-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00053-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=10\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00152-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00127-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=11\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00063-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00104-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=12\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00158-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00132-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=13\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00074-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00132-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=14\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00149-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00105-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=15\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00177-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00114-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=16\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00062-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00036-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=17\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00111-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00087-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=18\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00138-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00085-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=19\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00041-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00027-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=2\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00018-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00168-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=3\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00031-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00104-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=4\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00134-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00153-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=5\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00021-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00153-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=6\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00054-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00026-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=7\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00018-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00165-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       ├── \u001b[01;34mDay=8\u001b[00m\n",
      "│       │   ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│       │   │   └── part-00021-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       │   └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│       │       └── part-00184-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│       └── \u001b[01;34mDay=9\u001b[00m\n",
      "│           ├── \u001b[01;34mCountry=AU\u001b[00m\n",
      "│           │   └── part-00032-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "│           └── \u001b[01;34mCountry=CN\u001b[00m\n",
      "│               └── part-00146-9275ac39-b2ca-4aa9-b66d-7290e54ff769.c000.csv\n",
      "└── _SUCCESS\n",
      "\n",
      "153 directories, 101 files\n"
     ]
    }
   ],
   "source": [
    "!tree /tmp/df_tes/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-advisory",
   "metadata": {},
   "source": [
    "**Read from partitioned data**\n",
    "\n",
    "Now let’s read the data from the partitioned files with the these criteria:\n",
    "\n",
    "    Year= 2019\n",
    "    Month=2\n",
    "    Day=1\n",
    "    Country=CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "champion-fundamental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "+----------+------+\n",
      "|       _c0|   _c1|\n",
      "+----------+------+\n",
      "|      Date|Amount|\n",
      "|2019-02-01|    41|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/tmp/df_tes/Year=2019/Month=2/Day=1/Country=CN\")\n",
    "print(df.rdd.getNumPartitions()) # only one becaise there is only one record\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-couple",
   "metadata": {},
   "source": [
    "Similarly, we can also query all the data for the second month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "valuable-painting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "+----------+------+---+-------+\n",
      "|       _c0|   _c1|Day|Country|\n",
      "+----------+------+---+-------+\n",
      "|      Date|Amount|  3|     CN|\n",
      "|2019-02-03|    43|  3|     CN|\n",
      "|      Date|Amount| 10|     CN|\n",
      "|2019-02-10|    50| 10|     CN|\n",
      "|      Date|Amount| 13|     CN|\n",
      "|2019-02-13|    53| 13|     CN|\n",
      "|      Date|Amount| 16|     AU|\n",
      "|2019-02-16|    56| 16|     AU|\n",
      "|      Date|Amount| 15|     CN|\n",
      "|2019-02-15|    55| 15|     CN|\n",
      "|      Date|Amount| 16|     CN|\n",
      "|2019-02-16|    56| 16|     CN|\n",
      "|      Date|Amount| 17|     CN|\n",
      "|2019-02-17|    57| 17|     CN|\n",
      "|      Date|Amount| 10|     AU|\n",
      "|2019-02-10|    50| 10|     AU|\n",
      "|      Date|Amount|  5|     AU|\n",
      "|2019-02-05|    45|  5|     AU|\n",
      "|      Date|Amount| 15|     AU|\n",
      "|2019-02-15|    55| 15|     AU|\n",
      "+----------+------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/tmp/df_tes/Year=2019/Month=2\")\n",
    "print(df.rdd.getNumPartitions())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-norway",
   "metadata": {},
   "source": [
    "**Use wildcards for partition discovery**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "apparent-genius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "+----------+------+----+-----+---+-------+\n",
      "|       _c0|   _c1|Year|Month|Day|Country|\n",
      "+----------+------+----+-----+---+-------+\n",
      "|      Date|Amount|2019|    2|  3|     CN|\n",
      "|2019-02-03|    43|2019|    2|  3|     CN|\n",
      "|      Date|Amount|2019|    1| 17|     CN|\n",
      "|2019-01-17|    26|2019|    1| 17|     CN|\n",
      "|      Date|Amount|2019|    2| 10|     CN|\n",
      "|2019-02-10|    50|2019|    2| 10|     CN|\n",
      "|      Date|Amount|2019|    1|  3|     CN|\n",
      "|2019-01-03|    12|2019|    1|  3|     CN|\n",
      "|      Date|Amount|2019|    1| 24|     CN|\n",
      "|2019-01-24|    33|2019|    1| 24|     CN|\n",
      "|      Date|Amount|2019|    2| 13|     CN|\n",
      "|2019-02-13|    53|2019|    2| 13|     CN|\n",
      "|      Date|Amount|2019|    1| 25|     CN|\n",
      "|2019-01-25|    34|2019|    1| 25|     CN|\n",
      "|      Date|Amount|2019|    1|  1|     CN|\n",
      "|2019-01-01|    10|2019|    1|  1|     CN|\n",
      "|      Date|Amount|2019|    1| 21|     CN|\n",
      "|2019-01-21|    30|2019|    1| 21|     CN|\n",
      "|      Date|Amount|2019|    2| 15|     CN|\n",
      "|2019-02-15|    55|2019|    2| 15|     CN|\n",
      "+----------+------+----+-----+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"basePath\", \"/tmp/df_tes/\").csv(\"/tmp/df_tes/Year=*/Month=*/Day=*/Country=CN\")\n",
    "print(df.rdd.getNumPartitions())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-hostel",
   "metadata": {},
   "source": [
    "We can use wildcards in any part of the path for partition discovery. For example, the following code looks data for month 2 of Country AU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "nonprofit-brass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "+----------+------+----+-----+---+-------+\n",
      "|       _c0|   _c1|Year|Month|Day|Country|\n",
      "+----------+------+----+-----+---+-------+\n",
      "|      Date|Amount|2019|    2| 16|     AU|\n",
      "|2019-02-16|    56|2019|    2| 16|     AU|\n",
      "|      Date|Amount|2019|    2| 10|     AU|\n",
      "|2019-02-10|    50|2019|    2| 10|     AU|\n",
      "|      Date|Amount|2019|    2|  5|     AU|\n",
      "|2019-02-05|    45|2019|    2|  5|     AU|\n",
      "|      Date|Amount|2019|    2| 15|     AU|\n",
      "|2019-02-15|    55|2019|    2| 15|     AU|\n",
      "|      Date|Amount|2019|    2| 12|     AU|\n",
      "|2019-02-12|    52|2019|    2| 12|     AU|\n",
      "|      Date|Amount|2019|    2|  1|     AU|\n",
      "|2019-02-01|    41|2019|    2|  1|     AU|\n",
      "|      Date|Amount|2019|    2|  8|     AU|\n",
      "|2019-02-08|    48|2019|    2|  8|     AU|\n",
      "|      Date|Amount|2019|    2|  6|     AU|\n",
      "|2019-02-06|    46|2019|    2|  6|     AU|\n",
      "|      Date|Amount|2019|    2| 14|     AU|\n",
      "|2019-02-14|    54|2019|    2| 14|     AU|\n",
      "|      Date|Amount|2019|    2| 13|     AU|\n",
      "|2019-02-13|    53|2019|    2| 13|     AU|\n",
      "+----------+------+----+-----+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"basePath\", \"/tmp/df_tes/\").csv(\"/tmp/df_tes/Year=*/Month=2/Day=*/Country=AU\")\n",
    "print(df.rdd.getNumPartitions())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-poland",
   "metadata": {},
   "source": [
    "## Data Partitioning Functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "functional-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.rdd import portable_hash\n",
    "from pyspark import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eleven-calvin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---+\n",
      "|Amount|Country| ID|\n",
      "+------+-------+---+\n",
      "|    11|     AU|  1|\n",
      "|    12|     US|  2|\n",
      "|    13|     CN|  3|\n",
      "|    14|     AU|  4|\n",
      "|    15|     US|  5|\n",
      "|    16|     CN|  6|\n",
      "|    17|     AU|  7|\n",
      "|    18|     US|  8|\n",
      "|    19|     CN|  9|\n",
      "|    20|     AU| 10|\n",
      "|    21|     US| 11|\n",
      "|    22|     CN| 12|\n",
      "+------+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Populate sample data\n",
    "countries = (\"CN\", \"AU\", \"US\")\n",
    "data = []\n",
    "for i in range(1, 13):\n",
    "    data.append({\"ID\": i, \"Country\": countries[i % 3],  \"Amount\": 10+i})\n",
    "\n",
    "df = spark.createDataFrame(data)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "progressive-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_partitions(df):\n",
    "    numPartitions = df.rdd.getNumPartitions()\n",
    "    print(\"Total partitions: {}\\n\".format(numPartitions))\n",
    "    print(\"Partitioner: {}\\n\".format(df.rdd.partitioner))\n",
    "    df.explain()\n",
    "    print(\"\\n\")\n",
    "    parts = df.rdd.glom().collect()\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for p in parts:\n",
    "        print(\"\\nPartition {}:\".format(i))\n",
    "        for r in p:\n",
    "            print(\"Row {}:{}\".format(j, r))\n",
    "            j = j+1\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "assumed-silicon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total partitions: 10\n",
      "\n",
      "Partitioner: None\n",
      "\n",
      "== Physical Plan ==\n",
      "Scan ExistingRDD[Amount#744L,Country#745,ID#746L]\n",
      "\n",
      "\n",
      "\n",
      "Partition 0:\n",
      "Row 0:Row(Amount=11, Country='AU', ID=1)\n",
      "\n",
      "Partition 1:\n",
      "Row 1:Row(Amount=12, Country='US', ID=2)\n",
      "\n",
      "Partition 2:\n",
      "Row 2:Row(Amount=13, Country='CN', ID=3)\n",
      "\n",
      "Partition 3:\n",
      "Row 3:Row(Amount=14, Country='AU', ID=4)\n",
      "\n",
      "Partition 4:\n",
      "Row 4:Row(Amount=15, Country='US', ID=5)\n",
      "Row 5:Row(Amount=16, Country='CN', ID=6)\n",
      "\n",
      "Partition 5:\n",
      "Row 6:Row(Amount=17, Country='AU', ID=7)\n",
      "\n",
      "Partition 6:\n",
      "Row 7:Row(Amount=18, Country='US', ID=8)\n",
      "\n",
      "Partition 7:\n",
      "Row 8:Row(Amount=19, Country='CN', ID=9)\n",
      "\n",
      "Partition 8:\n",
      "Row 9:Row(Amount=20, Country='AU', ID=10)\n",
      "\n",
      "Partition 9:\n",
      "Row 10:Row(Amount=21, Country='US', ID=11)\n",
      "Row 11:Row(Amount=22, Country='CN', ID=12)\n"
     ]
    }
   ],
   "source": [
    "print_partitions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "threaded-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(3, \"Country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fiscal-rhythm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total partitions: 3\n",
      "\n",
      "Partitioner: None\n",
      "\n",
      "== Physical Plan ==\n",
      "Exchange hashpartitioning(Country#745, 3)\n",
      "+- Scan ExistingRDD[Amount#744L,Country#745,ID#746L]\n",
      "\n",
      "\n",
      "\n",
      "Partition 0:\n",
      "\n",
      "Partition 1:\n",
      "Row 0:Row(Amount=12, Country='US', ID=2)\n",
      "Row 1:Row(Amount=13, Country='CN', ID=3)\n",
      "Row 2:Row(Amount=18, Country='US', ID=8)\n",
      "Row 3:Row(Amount=15, Country='US', ID=5)\n",
      "Row 4:Row(Amount=16, Country='CN', ID=6)\n",
      "Row 5:Row(Amount=19, Country='CN', ID=9)\n",
      "Row 6:Row(Amount=21, Country='US', ID=11)\n",
      "Row 7:Row(Amount=22, Country='CN', ID=12)\n",
      "\n",
      "Partition 2:\n",
      "Row 8:Row(Amount=11, Country='AU', ID=1)\n",
      "Row 9:Row(Amount=17, Country='AU', ID=7)\n",
      "Row 10:Row(Amount=14, Country='AU', ID=4)\n",
      "Row 11:Row(Amount=20, Country='AU', ID=10)\n"
     ]
    }
   ],
   "source": [
    "print_partitions(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-marsh",
   "metadata": {},
   "source": [
    "**You may expect that each partition includes data for each Country but that is not the case. Why? Because repartition function by default uses hash partitioning. For different country code, it may be allocated into the same partition number.**\n",
    "We can verify this by using the following code to calculate the hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "printable-supplier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---+--------------------+----------+\n",
      "|Amount|Country| ID|               Hash#|Partition#|\n",
      "+------+-------+---+--------------------+----------+\n",
      "|    13|     CN|  3|-7458853143580063552|      -1.0|\n",
      "|    19|     CN|  9|-7458853143580063552|      -1.0|\n",
      "|    12|     US|  2|-8328537658613580243|      -1.0|\n",
      "|    18|     US|  8|-8328537658613580243|      -1.0|\n",
      "|    15|     US|  5|-8328537658613580243|      -1.0|\n",
      "|    16|     CN|  6|-7458853143580063552|      -1.0|\n",
      "|    21|     US| 11|-8328537658613580243|      -1.0|\n",
      "|    22|     CN| 12|-7458853143580063552|      -1.0|\n",
      "|    14|     AU|  4| 6593628092971972691|       0.0|\n",
      "|    20|     AU| 10| 6593628092971972691|       0.0|\n",
      "|    11|     AU|  1| 6593628092971972691|       0.0|\n",
      "|    17|     AU|  7| 6593628092971972691|       0.0|\n",
      "+------+-------+---+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "udf_portable_hash = F.udf(lambda str: portable_hash(str))\n",
    "df = df.withColumn(\"Hash#\", udf_portable_hash(df.Country))\n",
    "df = df.withColumn(\"Partition#\", df[\"Hash#\"] % 3)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-company",
   "metadata": {},
   "source": [
    "The output shows that each country’s data is now located in the same partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "serial-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = (\"CN\", \"AU\", \"US\")\n",
    "def country_partitioning(k):\n",
    "    return countries.index(k)\n",
    "    \n",
    "udf_country_hash = F.udf(lambda str: country_partitioning(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "possible-payment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---+-----+----------+\n",
      "|Amount|Country| ID|Hash#|Partition#|\n",
      "+------+-------+---+-----+----------+\n",
      "|    11|     AU|  1|    1|       1.0|\n",
      "|    17|     AU|  7|    1|       1.0|\n",
      "|    14|     AU|  4|    1|       1.0|\n",
      "|    20|     AU| 10|    1|       1.0|\n",
      "|    16|     CN|  6|    0|       0.0|\n",
      "|    22|     CN| 12|    0|       0.0|\n",
      "|    13|     CN|  3|    0|       0.0|\n",
      "|    19|     CN|  9|    0|       0.0|\n",
      "|    15|     US|  5|    2|       2.0|\n",
      "|    18|     US|  8|    2|       2.0|\n",
      "|    21|     US| 11|    2|       2.0|\n",
      "|    12|     US|  2|    2|       2.0|\n",
      "+------+-------+---+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numPartitions = 3\n",
    "# df = df.partitionBy(numPartitions, country_partitioning)\n",
    "df = df.withColumn(\"Hash#\", udf_country_hash(df['Country']))\n",
    "df = df.withColumn(\"Partition#\", df[\"Hash#\"] % numPartitions)\n",
    "df.orderBy('Country').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "purple-replication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total partitions: 3\n",
      "\n",
      "Partitioner: None\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [Amount#744L, Country#745, ID#746L, pythonUDF1#894 AS Hash##863, (cast(pythonUDF1#894 as double) % 3.0) AS Partition##869]\n",
      "+- BatchEvalPython [<lambda>(Country#745), <lambda>(Country#745)], [Amount#744L, Country#745, ID#746L, pythonUDF0#893, pythonUDF1#894]\n",
      "   +- Exchange hashpartitioning(Country#745, 3)\n",
      "      +- Scan ExistingRDD[Amount#744L,Country#745,ID#746L]\n",
      "\n",
      "\n",
      "\n",
      "Partition 0:\n",
      "\n",
      "Partition 1:\n",
      "Row 0:Row(Amount=12, Country='US', ID=2, Hash#='2', Partition#=2.0)\n",
      "Row 1:Row(Amount=18, Country='US', ID=8, Hash#='2', Partition#=2.0)\n",
      "Row 2:Row(Amount=13, Country='CN', ID=3, Hash#='0', Partition#=0.0)\n",
      "Row 3:Row(Amount=19, Country='CN', ID=9, Hash#='0', Partition#=0.0)\n",
      "Row 4:Row(Amount=15, Country='US', ID=5, Hash#='2', Partition#=2.0)\n",
      "Row 5:Row(Amount=16, Country='CN', ID=6, Hash#='0', Partition#=0.0)\n",
      "Row 6:Row(Amount=21, Country='US', ID=11, Hash#='2', Partition#=2.0)\n",
      "Row 7:Row(Amount=22, Country='CN', ID=12, Hash#='0', Partition#=0.0)\n",
      "\n",
      "Partition 2:\n",
      "Row 8:Row(Amount=14, Country='AU', ID=4, Hash#='1', Partition#=1.0)\n",
      "Row 9:Row(Amount=20, Country='AU', ID=10, Hash#='1', Partition#=1.0)\n",
      "Row 10:Row(Amount=11, Country='AU', ID=1, Hash#='1', Partition#=1.0)\n",
      "Row 11:Row(Amount=17, Country='AU', ID=7, Hash#='1', Partition#=1.0)\n"
     ]
    }
   ],
   "source": [
    "print_partitions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "verbal-yellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total partitions: 3\n",
      "\n",
      "Partitioner: None\n",
      "\n",
      "== Physical Plan ==\n",
      "Exchange hashpartitioning(Partition##869, 3)\n",
      "+- *(1) Project [Amount#744L, Country#745, ID#746L, pythonUDF1#898 AS Hash##863, (cast(pythonUDF1#898 as double) % 3.0) AS Partition##869]\n",
      "   +- BatchEvalPython [<lambda>(Country#745), <lambda>(Country#745)], [Amount#744L, Country#745, ID#746L, pythonUDF0#897, pythonUDF1#898]\n",
      "      +- Exchange hashpartitioning(Country#745, 3)\n",
      "         +- Scan ExistingRDD[Amount#744L,Country#745,ID#746L]\n",
      "\n",
      "\n",
      "\n",
      "Partition 0:\n",
      "Row 0:Row(Amount=15, Country='US', ID=5, Hash#='2', Partition#=2.0)\n",
      "Row 1:Row(Amount=21, Country='US', ID=11, Hash#='2', Partition#=2.0)\n",
      "Row 2:Row(Amount=12, Country='US', ID=2, Hash#='2', Partition#=2.0)\n",
      "Row 3:Row(Amount=18, Country='US', ID=8, Hash#='2', Partition#=2.0)\n",
      "\n",
      "Partition 1:\n",
      "Row 4:Row(Amount=13, Country='CN', ID=3, Hash#='0', Partition#=0.0)\n",
      "Row 5:Row(Amount=19, Country='CN', ID=9, Hash#='0', Partition#=0.0)\n",
      "Row 6:Row(Amount=16, Country='CN', ID=6, Hash#='0', Partition#=0.0)\n",
      "Row 7:Row(Amount=22, Country='CN', ID=12, Hash#='0', Partition#=0.0)\n",
      "\n",
      "Partition 2:\n",
      "Row 8:Row(Amount=14, Country='AU', ID=4, Hash#='1', Partition#=1.0)\n",
      "Row 9:Row(Amount=20, Country='AU', ID=10, Hash#='1', Partition#=1.0)\n",
      "Row 10:Row(Amount=11, Country='AU', ID=1, Hash#='1', Partition#=1.0)\n",
      "Row 11:Row(Amount=17, Country='AU', ID=7, Hash#='1', Partition#=1.0)\n"
     ]
    }
   ],
   "source": [
    "print_partitions(df.repartition(3, \"Partition#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-outdoors",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
