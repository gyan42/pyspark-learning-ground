{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "french-disclaimer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMSSpamCollection.txt  out  simple_text.txt\n"
     ]
    }
   ],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "parliamentary-russia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-28 23:59:49--  https://hrcdn.net/s3_pub/istreet-assets/H4_TQkbOj39HUNoBukluIQ/training.txt\n",
      "Resolving hrcdn.net (hrcdn.net)... 23.212.254.99, 23.212.254.56, 2600:140f:4::6011:960b, ...\n",
      "Connecting to hrcdn.net (hrcdn.net)|23.212.254.99|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: 'training.txt'\n",
      "\n",
      "training.txt            [   <=>              ] 444.49K   708KB/s    in 0.6s    \n",
      "\n",
      "2021-02-28 23:59:50 (708 KB/s) - 'training.txt' saved [455154]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://hrcdn.net/s3_pub/istreet-assets/H4_TQkbOj39HUNoBukluIQ/training.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cooperative-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_csv('training.txt', \n",
    "                       sep='\\t', \n",
    "                       quoting=csv.QUOTE_NONE,\n",
    "                       names=[\"label\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "subsequent-sharing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3091</td>\n",
       "      <td>639</td>\n",
       "      <td>I hate Harry Potter.</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3995</td>\n",
       "      <td>772</td>\n",
       "      <td>I love Harry Potter.</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                  \n",
       "        count unique                   top freq\n",
       "label                                          \n",
       "0        3091    639  I hate Harry Potter.   86\n",
       "1        3995    772  I love Harry Potter.  167"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "based-engine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5574\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "#Data Loading\n",
    "messages = [line.rstrip() for line in open('data/SMSSpamCollection.txt')]\n",
    "print(len(messages))\n",
    "#Appending column headers\n",
    "messages = pd.read_csv('data/SMSSpamCollection.txt', \n",
    "                       sep='\\t', \n",
    "                       quoting=csv.QUOTE_NONE,\n",
    "                       names=[\"label\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "orange-allen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5569  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5570   ham               Will ü b going to esplanade fr home?\n",
       "5571   ham  Pity, * was in mood for that. So...any other s...\n",
       "5572   ham  The guy did some bitching but I acted like i'd...\n",
       "5573   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contrary-patch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 2)\n"
     ]
    }
   ],
   "source": [
    "data_size=messages.shape\n",
    "print(data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "signed-adjustment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['label', 'message']\n"
     ]
    }
   ],
   "source": [
    "messages_col_names=list(messages.columns)\n",
    "print(messages_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "excited-bacteria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      message                                                               \n",
      "        count unique                                                top freq\n",
      "label                                                                       \n",
      "ham      4827   4518                             Sorry, I'll call later   30\n",
      "spam      747    653  Please call our customer service representativ...    4\n"
     ]
    }
   ],
   "source": [
    "print(messages.groupby('label').describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "standing-decade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        ham\n",
      "1        ham\n",
      "2       spam\n",
      "3        ham\n",
      "4        ham\n",
      "        ... \n",
      "5569    spam\n",
      "5570     ham\n",
      "5571     ham\n",
      "5572     ham\n",
      "5573     ham\n",
      "Name: label, Length: 5574, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Identifying the outcome/target variable.\n",
    "message_target=messages['label'] \n",
    "print(message_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "warming-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] >= 3:\n",
    "    unicode = str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "numerous-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('all')\n",
    "from nltk.tokenize import word_tokenize\n",
    "def split_tokens(message):\n",
    "  message=message.lower()\n",
    "#   message = unicode(message, 'utf8') #convert bytes into proper unicode\n",
    "  word_tokens =word_tokenize(message)\n",
    "  return word_tokens\n",
    "messages['tokenized_message'] = messages.apply(lambda row: split_tokens(row['message']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "phantom-twelve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'not',\n",
       " 'do',\n",
       " 'great',\n",
       " 'things',\n",
       " ',',\n",
       " 'do',\n",
       " 'small',\n",
       " 'things',\n",
       " 'in',\n",
       " 'a',\n",
       " 'great',\n",
       " 'way']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_tokens(\"if you cannot do great things, do small things in a great way\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "competitive-latin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized message: ['six', 'chances', 'to', 'win', 'cash', '!', 'from', '100', 'to', '20,000', 'pounds', 'txt', '>', 'csh11', 'and', 'send', 'to', '87575.', 'cost', '150p/day', ',', '6days', ',', '16+', 'tsandcs', 'apply', 'reply', 'hl', '4', 'info']\n",
      "Lemmatized message: ['six', 'chance', 'to', 'win', 'cash', '!', 'from', '100', 'to', '20,000', 'pound', 'txt', '>', 'csh11', 'and', 'send', 'to', '87575.', 'cost', '150p/day', ',', '6days', ',', '16+', 'tsandcs', 'apply', 'reply', 'hl', '4', 'info']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def split_into_lemmas(message):\n",
    "    lemma = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word in message:\n",
    "        a=lemmatizer.lemmatize(word)\n",
    "        lemma.append(a)\n",
    "    return lemma\n",
    "messages['lemmatized_message'] = messages.apply(lambda row: split_into_lemmas(row['tokenized_message']),axis=1)\n",
    "print('Tokenized message:',messages['tokenized_message'][11])\n",
    "print('Lemmatized message:',messages['lemmatized_message'][11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "perceived-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def stopword_removal(message):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_sentence = []\n",
    "    filtered_sentence = ' '.join([word for word in message if word not in stop_words])\n",
    "    return filtered_sentence\n",
    "messages['preprocessed_message'] = messages.apply(lambda row: stopword_removal(row['lemmatized_message']),axis=1)\n",
    "Training_data=pd.Series(list(messages['preprocessed_message']))\n",
    "Training_label=pd.Series(list(messages['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "psychological-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2),\n",
    "                                   min_df = (1/len(Training_label)), \n",
    "                                   max_df = 0.7)\n",
    "Total_Dictionary_TFIDF = tfidf_vectorizer.fit(Training_data)\n",
    "message_data_TFIDF = Total_Dictionary_TFIDF.transform(Training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "primary-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "tf_vectorizer = CountVectorizer(ngram_range=(1, 2),min_df = (1/len(Training_label)), max_df = 0.7)\n",
    "Total_Dictionary_TDM = tf_vectorizer.fit(Training_data)\n",
    "message_data_TDM = Total_Dictionary_TDM.transform(Training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bizarre-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split#Splitting the data for training and testing\n",
    "train_data,test_data, train_label, test_label = train_test_split(message_data_TDM, Training_label, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afraid-antigua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3955     ham\n",
       "5279     ham\n",
       "4241     ham\n",
       "47       ham\n",
       "312     spam\n",
       "        ... \n",
       "4559     ham\n",
       "3679    spam\n",
       "455     spam\n",
       "4109     ham\n",
       "5342     ham\n",
       "Length: 558, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "unique-conditioning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier :  0.978494623655914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier#Creating a decision classifier model\n",
    "classifier=DecisionTreeClassifier() #Model training\n",
    "classifier = classifier.fit(train_data, train_label) #After being fitted, the model can then be used to predict the output.\n",
    "message_predicted_target = classifier.predict(test_data)\n",
    "score = classifier.score(test_data, test_label)\n",
    "print('Decision Tree Classifier : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "collectible-variety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD classifier :  0.989247311827957\n"
     ]
    }
   ],
   "source": [
    "seed=7\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier =  SGDClassifier(loss='modified_huber', shuffle=True,random_state=seed)\n",
    "classifier = classifier.fit(train_data, train_label)\n",
    "score = classifier.score(test_data, test_label)\n",
    "print('SGD classifier : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bound-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier :  0.9838709677419355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel=\"linear\", C=0.025,random_state=seed)\n",
    "classifier = classifier.fit(train_data, train_label)\n",
    "score = classifier.score(test_data, test_label)\n",
    "print('SVM Classifier : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adolescent-jenny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier :  0.8763440860215054\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=10,random_state=seed)\n",
    "classifier = classifier.fit(train_data, train_label)\n",
    "score = classifier.score(test_data, test_label)\n",
    "print('Random Forest Classifier : ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "rational-awareness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classification after model tuning 0.8763440860215054\n"
     ]
    }
   ],
   "source": [
    "# Tuning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(max_depth=5, n_estimators=15, max_features=60,random_state=seed)\n",
    "classifier = classifier.fit(train_data, train_label)\n",
    "score=classifier.score(test_data, test_label)\n",
    "print('Random Forest classification after model tuning',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "heard-oregon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=1, random_state=7, test_size=0.1,\n",
      "            train_size=None)\n"
     ]
    }
   ],
   "source": [
    "seed=7\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "###cross validation with 10% sample size\n",
    "sss = StratifiedShuffleSplit(n_splits=1,test_size=0.1, random_state=seed)\n",
    "sss.get_n_splits(message_data_TDM,Training_label)\n",
    "print(sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "designed-grounds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9695340501792115\n",
      "0.96415770609319\n",
      "0.9695340501792115\n",
      "0.9014336917562724\n",
      "0.974910394265233\n",
      "0.8655913978494624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import svm\n",
    "classifiers = [\n",
    "    DecisionTreeClassifier(),\n",
    "    SGDClassifier(loss='modified_huber', shuffle=True),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    KNeighborsClassifier(),\n",
    "    OneVsRestClassifier(svm.LinearSVC()),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=10),\n",
    "   ]\n",
    "for clf in classifiers:\n",
    "    score=0\n",
    "    for train_index, test_index in sss.split(message_data_TDM,Training_label):\n",
    "        X_train, X_test = message_data_TDM [train_index], message_data_TDM [test_index]\n",
    "        y_train, y_test = Training_label[train_index], Training_label[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        score=score+clf.score(X_test, y_test)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "generous-elder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.978494623655914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ham     489\n",
       "spam     69\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy Score',accuracy_score(test_label,message_predicted_target))  \n",
    "classifier = classifier.fit(train_data, train_label)\n",
    "score=classifier.score(test_data, test_label)\n",
    "test_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "headed-israeli",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[486   3]\n",
      " [  9  60]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix\\n',confusion_matrix(test_label,message_predicted_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "assigned-cathedral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        spam       0.98      0.99      0.99       489\n",
      "         ham       0.95      0.87      0.91        69\n",
      "\n",
      "    accuracy                           0.98       558\n",
      "   macro avg       0.97      0.93      0.95       558\n",
      "weighted avg       0.98      0.98      0.98       558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['spam', 'ham']\n",
    "print(classification_report(test_label, message_predicted_target, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-excess",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
