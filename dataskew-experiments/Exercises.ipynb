{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row\n",
    "from numpy.random import rand\n",
    "from pyspark.sql.types import IntegerType, StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My machine has following configuration...\n",
    "- 6 cores with 12vCores\n",
    "- 32GB RAM\n",
    "\n",
    "Spark Standalone server:\n",
    "```\n",
    "cd /opt/binaries/spark-2.4.5-bin-hadoop2.7/\n",
    "sbin/start-all.sh\n",
    "sbin/stop-all.sh\n",
    "```\n",
    "Spark UI: [http://localhost:8080](http://localhost:8080)   \n",
    "Spark MAster URL : spark://IMCHLT276:7077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://IMCHLT276:7077\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.cores.max\", \"8\") \\\n",
    "    .config(\"spark.local.dir\", \"/opt/tmp/spark-temp/\") \\\n",
    "    .appName(\"Warmup1\") \\\n",
    "    .getOrCreate()\n",
    "# https://stackoverflow.com/questions/27774443/is-it-safe-to-temporarily-rename-tmp-and-then-create-a-tmp-symlink-to-a-differe\n",
    "# sudo mount --bind /path/to/dir/with/plenty/of/space /tmp\n",
    "# sudo lsof /tmp # check for apps\n",
    "# sudo umount /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.142:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://IMCHLT276:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Warmup1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0081c58c88>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Products  \n",
    "--------\n",
    ": product_id - The product ID  \n",
    ": product_name  - The product name   \n",
    ": price - The product price   \n",
    "\n",
    "Sellers  \n",
    "-------\n",
    ": seller_id  - The seller ID   \n",
    ": seller_name  - The seller name    \n",
    ": daily_target - The number of items (regardless of the product type) that the seller needs to hit his/her quota. For example, if the daily target is 100,000, the employee needs to sell 100,000 products he can hit the quota by selling 100,000 units of product_0, but also selling 30,000 units of product_1 and 70,000 units of product_2   \n",
    "\n",
    "Sales  \n",
    "-----\n",
    ": order_id  - The order ID   \n",
    ": product_id  - The single product sold in the order. All orders have exactly one product)   \n",
    ": seller_id  - The selling employee ID that sold the product   \n",
    ": date - The date of the order.    \n",
    ": num_pieces_sold - The number of units sold for the specific product in the order    \n",
    ": bill_raw_text  -  A string that represents the raw text of the bill associated with the order   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(path, is_print=False):\n",
    "    if is_print: print(f\"\\nReading {path}\")\n",
    "    df = spark.read.parquet(path)\n",
    "    if is_print: df.show()\n",
    "    if is_print: print(f\"Number of records in {path} is {df.count()}\" )\n",
    "    if is_print: print(\"_\"*80 + \"\\n\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df, sales_df, sellers_df = None, None, None\n",
    "def reload(is_print=False):\n",
    "    global products_df, sales_df, sellers_df\n",
    "    products_df = read_df(\"../products_parquet\", is_print=is_print)\n",
    "    sales_df = read_df(\"../sales_parquet/\", is_print=is_print)\n",
    "    sellers_df = read_df(\"../sellers_parquet\", is_print=is_print)\n",
    "#     return products_df, sales_df, sellers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ../products_parquet\n",
      "+----------+------------+-----+\n",
      "|product_id|product_name|price|\n",
      "+----------+------------+-----+\n",
      "|         0|   product_0|   22|\n",
      "|         1|   product_1|   30|\n",
      "|         2|   product_2|   91|\n",
      "|         3|   product_3|   37|\n",
      "|         4|   product_4|  145|\n",
      "|         5|   product_5|  128|\n",
      "|         6|   product_6|   66|\n",
      "|         7|   product_7|  145|\n",
      "|         8|   product_8|   51|\n",
      "|         9|   product_9|   44|\n",
      "|        10|  product_10|   53|\n",
      "|        11|  product_11|   13|\n",
      "|        12|  product_12|  104|\n",
      "|        13|  product_13|  102|\n",
      "|        14|  product_14|   24|\n",
      "|        15|  product_15|   14|\n",
      "|        16|  product_16|   38|\n",
      "|        17|  product_17|   72|\n",
      "|        18|  product_18|   16|\n",
      "|        19|  product_19|   46|\n",
      "+----------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of records in ../products_parquet is 75000000\n",
      "________________________________________________________________________________\n",
      "\n",
      "\n",
      "Reading ../sales_parquet/\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "|order_id|product_id|seller_id|      date|num_pieces_sold|       bill_raw_text|\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "|       1|         0|        0|2020-07-10|             26|kyeibuumwlyhuwksx...|\n",
      "|       2|         0|        0|2020-07-08|             13|jfyuoyfkeyqkckwbu...|\n",
      "|       3|         0|        0|2020-07-05|             38|uyjihlzhzcswxcccx...|\n",
      "|       4|         0|        0|2020-07-05|             56|umnxvoqbdzpbwjqmz...|\n",
      "|       5|         0|        0|2020-07-05|             11|zmqexmaawmvdpqhih...|\n",
      "|       6|         0|        0|2020-07-01|             82|lmuhhkpyuoyslwmvX...|\n",
      "|       7|         0|        0|2020-07-04|             15|zoqweontumefxbgvu...|\n",
      "|       8|         0|        0|2020-07-08|             79|sgldfgtcxufasnvsc...|\n",
      "|       9|         0|        0|2020-07-10|             25|jnykelwjjebgkwgmu...|\n",
      "|      10|         0|        0|2020-07-08|              8|yywjfihneygcvfnyl...|\n",
      "|      11|         0|        0|2020-07-01|             10|nxwejyoeznltdhcam...|\n",
      "|      12|         0|        0|2020-07-06|             45|efmymeftivwsfljzt...|\n",
      "|      13|         0|        0|2020-07-10|             63|nxhvtospPhfnkavdy...|\n",
      "|      14|         0|        0|2020-07-03|             22|ypyusdsjzfpfbucnn...|\n",
      "|      15|         0|        0|2020-07-09|             75|ymjvbhaxffyjcwzyn...|\n",
      "|      16|         0|        0|2020-07-10|             83|phbcykkhvqsbkipwa...|\n",
      "|      17|         0|        0|2020-07-04|             54|qgnGqqnjmbqZytoug...|\n",
      "|      18|         0|        0|2020-07-04|             58|ozmllbabrnhebWcex...|\n",
      "|      19|         0|        0|2020-07-07|             33|kbrvXuzgiuinodtkg...|\n",
      "|      20|         0|        0|2020-07-09|             73|jnqjzaigjtqlfwpug...|\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of records in ../sales_parquet/ is 20000040\n",
      "________________________________________________________________________________\n",
      "\n",
      "\n",
      "Reading ../sellers_parquet\n",
      "+---------+-----------+------------+\n",
      "|seller_id|seller_name|daily_target|\n",
      "+---------+-----------+------------+\n",
      "|        0|   seller_0|     2500000|\n",
      "|        1|   seller_1|      257237|\n",
      "|        2|   seller_2|      754188|\n",
      "|        3|   seller_3|      310462|\n",
      "|        4|   seller_4|     1532808|\n",
      "|        5|   seller_5|     1199693|\n",
      "|        6|   seller_6|     1055915|\n",
      "|        7|   seller_7|     1946998|\n",
      "|        8|   seller_8|      547320|\n",
      "|        9|   seller_9|     1318051|\n",
      "+---------+-----------+------------+\n",
      "\n",
      "Number of records in ../sellers_parquet is 10\n",
      "________________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reload(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warmup - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Find out how many orders, how many products and how many sellers are in the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sellers no: 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sellers no: {sellers_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products no: 75000000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Products no: {products_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales no: 20000040\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sales no: {sales_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How many products have been sold at least once?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of products sold at least once\n",
      "+--------------------------+\n",
      "|count(DISTINCT product_id)|\n",
      "+--------------------------+\n",
      "|                    993429|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of products sold at least once\")\n",
    "sales_df.agg(F.countDistinct(F.col(\"product_id\"))).show()\n",
    "# sales_df.agg({\"product_id\" : \"countDistinct\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|count(DISTINCT product_id)|\n",
      "+--------------------------+\n",
      "|                    993429|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.select(F.countDistinct(F.col(\"product_id\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Which is the product contained in more orders?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|product_id|     cnt|\n",
      "+----------+--------+\n",
      "|         0|19000000|\n",
      "+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.groupBy(\"product_id\")\\\n",
    "    .agg(F.count(\"*\").alias(\"cnt\"))\\\n",
    "    .orderBy(F.col(\"cnt\").desc())\\\n",
    "    .limit(1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. How many distinct products have been sold in each day?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      date|   cnt|\n",
      "+----------+------+\n",
      "|2020-07-06|100765|\n",
      "|2020-07-09|100501|\n",
      "|2020-07-01|100337|\n",
      "|2020-07-03|100017|\n",
      "|2020-07-02| 99807|\n",
      "|2020-07-05| 99796|\n",
      "|2020-07-04| 99791|\n",
      "|2020-07-07| 99756|\n",
      "|2020-07-08| 99662|\n",
      "|2020-07-10| 98973|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.groupBy(\"date\") \\\n",
    "        .agg(F.countDistinct(F.col(\"product_id\")).alias(\"cnt\"))\\\n",
    "        .orderBy(F.col(\"cnt\").desc()) \\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.What is the average revenue of the orders?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# products_df.join(sales_df, on=\"product_id\", how=\"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# products_df = products_df.repartition(128)\n",
    "# sales_df = sales_df.repartition(256)\n",
    "#  products_df.join(sales_df, on=\"product_id\").count() ### Will end up as timeout error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# products_df = products_df.withColumnRenamed(\"product_id\", \"repartition_id\").repartition(512, F.col(\"repartition_id\"))\n",
    "# sales_df = sales_df.withColumnRenamed(\"product_id\", \"repartition_id\").repartition(512, F.col(\"repartition_id\"))     \n",
    "# products_df.join(sales_df, on=\"repartition_id\").count() ### Will end up as timeout error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saltify(df, col_name, number_of_partition):\n",
    "  \"\"\"\n",
    "  Adds a new column names `col_name`_salted, which has concatenated values of `col_name` and number in the range of 0 to number_of_partition\n",
    "  Note: import pyspark.sql.functions as F\n",
    "  \"\"\"\n",
    "  salted_col = col_name + \"_salted\"  \n",
    "  return df.withColumn(\"dummy\", F.monotonically_increasing_id() % number_of_partition)\\\n",
    "            .withColumn(salted_col, F.concat(F.col(col_name), F.lit(\"-\"),F.col(\"dummy\")))\\\n",
    "            .drop(F.col(\"dummy\")).repartition(number_of_partition, F.col(salted_col)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = saltify(df=products_df, col_name=\"product_id\", number_of_partition=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# products_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = saltify(df=sales_df, col_name=\"product_id\", number_of_partition=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales_df.groupBy(\"product_id_salted\")\\\n",
    "#     .agg(F.count(\"*\").alias(\"cnt\"))\\\n",
    "#     .orderBy(F.col(\"cnt\").desc())\\\n",
    "#     .limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|avg((price * num_pieces_sold))|\n",
      "+------------------------------+\n",
      "|             1242.751587464154|\n",
      "+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "products_df.join(sales_df, on=\"product_id_salted\", how=\"inner\").agg(F.avg(products_df[\"price\"] * sales_df[\"num_pieces_sold\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Check and select the skewed keys \n",
    "# In this case we are retrieving the top 100 keys: these will be the only salted keys.\n",
    "results = sales_df.groupby(sales_df[\"product_id\"]).count().sort(F.col(\"count\").desc()).limit(100).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - What we want to do is:\n",
    "#  a. Duplicate the entries that we have in the dimension table for the most common products, e.g.\n",
    "#       product_0 will become: product_0-1, product_0-2, product_0-3 and so on\n",
    "#  b. On the sales table, we are going to replace \"product_0\" with a random duplicate (e.g. some of them \n",
    "#     will be replaced with product_0-1, others with product_0-2, etc.)\n",
    "# Using the new \"salted\" key will unskew the join\n",
    "\n",
    "# Let's create a dataset to do the trick\n",
    "REPLICATION_FACTOR = 101\n",
    "l = []\n",
    "replicated_products = []\n",
    "for _r in results:\n",
    "    replicated_products.append(_r[\"product_id\"])\n",
    "    for _rep in range(0, REPLICATION_FACTOR):\n",
    "        l.append((_r[\"product_id\"], _rep))\n",
    "        \n",
    "rdd = spark.sparkContext.parallelize(l)\n",
    "replicated_df = rdd.map(lambda x: Row(product_id=x[0], replication=int(x[1])))\n",
    "replicated_df = spark.createDataFrame(replicated_df)\n",
    "# replicated_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Step 3: Generate the salted key\n",
    "products_df = products_df.join(F.broadcast(replicated_df), products_df[\"product_id\"] == replicated_df[\"product_id\"], \"left\"). \\\n",
    "    withColumn(\"salted_join_key\", F.when(replicated_df[\"replication\"].isNull(), products_df[\"product_id\"]).otherwise(\n",
    "    F.concat(replicated_df[\"product_id\"], F.lit(\"-\"), replicated_df[\"replication\"])))\n",
    "\n",
    "# products_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = sales_df.withColumn(\"salted_join_key\", F.when(sales_df[\"product_id\"].isin(replicated_products),\n",
    "                                                             F.concat(sales_df[\"product_id\"], F.lit(\"-\"),\n",
    "                                                                    F.lit(round(rand() * (REPLICATION_FACTOR - 1), 0)).cast(\n",
    "                                                                        IntegerType()))).otherwise(sales_df[\"product_id\"]))\n",
    "# sales_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|avg((price * num_pieces_sold))|\n",
      "+------------------------------+\n",
      "|            1246.1338560822878|\n",
      "+------------------------------+\n",
      "\n",
      "None\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "#   Step 4: Finally let's do the join\n",
    "print(sales_df.join(products_df, sales_df[\"salted_join_key\"] == products_df[\"salted_join_key\"],\n",
    "                       \"inner\").\n",
    "      agg(F.avg(products_df[\"price\"] * sales_df[\"num_pieces_sold\"])).show())\n",
    "\n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. For each seller, what is the average % contribution of an order to the seller's daily quota?**\n",
    "\n",
    "Example   \n",
    "If Seller_0 with `quota=250` has 3 orders:Order 1: 10 products sold    \n",
    "Order 2: 8 products sold    \n",
    "Order 3: 7 products soldThe average % contribution of orders to the seller's quota would be:    \n",
    "Order 1: 10/105 = 0.04   \n",
    "Order 2: 8/105 = 0.032     \n",
    "Order 3: 7/105 = 0.028Average % Contribution = (0.04+0.032+0.028)/3 = 0.03333    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------+\n",
      "|seller_id|seller_name|daily_target|\n",
      "+---------+-----------+------------+\n",
      "|        0|   seller_0|     2500000|\n",
      "|        1|   seller_1|      257237|\n",
      "|        2|   seller_2|      754188|\n",
      "|        3|   seller_3|      310462|\n",
      "|        4|   seller_4|     1532808|\n",
      "|        5|   seller_5|     1199693|\n",
      "|        6|   seller_6|     1055915|\n",
      "|        7|   seller_7|     1946998|\n",
      "|        8|   seller_8|      547320|\n",
      "|        9|   seller_9|     1318051|\n",
      "+---------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sellers_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "|order_id|product_id|seller_id|      date|num_pieces_sold|       bill_raw_text|\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "|       1|         0|        0|2020-07-10|             26|kyeibuumwlyhuwksx...|\n",
      "|       2|         0|        0|2020-07-08|             13|jfyuoyfkeyqkckwbu...|\n",
      "|       3|         0|        0|2020-07-05|             38|uyjihlzhzcswxcccx...|\n",
      "|       4|         0|        0|2020-07-05|             56|umnxvoqbdzpbwjqmz...|\n",
      "|       5|         0|        0|2020-07-05|             11|zmqexmaawmvdpqhih...|\n",
      "|       6|         0|        0|2020-07-01|             82|lmuhhkpyuoyslwmvX...|\n",
      "|       7|         0|        0|2020-07-04|             15|zoqweontumefxbgvu...|\n",
      "|       8|         0|        0|2020-07-08|             79|sgldfgtcxufasnvsc...|\n",
      "|       9|         0|        0|2020-07-10|             25|jnykelwjjebgkwgmu...|\n",
      "|      10|         0|        0|2020-07-08|              8|yywjfihneygcvfnyl...|\n",
      "|      11|         0|        0|2020-07-01|             10|nxwejyoeznltdhcam...|\n",
      "|      12|         0|        0|2020-07-06|             45|efmymeftivwsfljzt...|\n",
      "|      13|         0|        0|2020-07-10|             63|nxhvtospPhfnkavdy...|\n",
      "|      14|         0|        0|2020-07-03|             22|ypyusdsjzfpfbucnn...|\n",
      "|      15|         0|        0|2020-07-09|             75|ymjvbhaxffyjcwzyn...|\n",
      "|      16|         0|        0|2020-07-10|             83|phbcykkhvqsbkipwa...|\n",
      "|      17|         0|        0|2020-07-04|             54|qgnGqqnjmbqZytoug...|\n",
      "|      18|         0|        0|2020-07-04|             58|ozmllbabrnhebWcex...|\n",
      "|      19|         0|        0|2020-07-07|             33|kbrvXuzgiuinodtkg...|\n",
      "|      20|         0|        0|2020-07-09|             73|jnqjzaigjtqlfwpug...|\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|seller_id|          avg(ratio)|\n",
      "+---------+--------------------+\n",
      "|        7|2.595228787788171E-5|\n",
      "|        3|1.628885370565939...|\n",
      "|        8| 9.21303037540886E-5|\n",
      "|        0|2.019885898946922...|\n",
      "|        5|4.211073965904021E-5|\n",
      "|        6|4.782147194369122E-5|\n",
      "|        9|3.837913136180238E-5|\n",
      "|        1|1.964233366461015E-4|\n",
      "|        4|3.296428039825816E-5|\n",
      "|        2|6.690408001060484E-5|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.join(F.broadcast(sellers_df), on=\"seller_id\", how=\"inner\")\\\n",
    ".withColumn(\"ratio\", sales_df[\"num_pieces_sold\"]/sellers_df[\"daily_target\"])\\\n",
    ".groupBy(\"seller_id\").agg(F.avg(\"ratio\")).alias(\"percent\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.Who are the second most selling and the least selling persons (sellers) for each product? Who are those for product with `product_id = 0`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.**\n",
    "```\n",
    "Create a new column called \"hashed_bill\" defined as follows:\n",
    "\n",
    "- if the order_id is even: apply MD5 hashing iteratively to the bill_raw_text field, once for each 'A' (capital 'A') present in the text. E.g. if the bill text is 'nbAAnllA', you would apply hashing three times iteratively (only if the order number is even)\n",
    "\n",
    "- if the order_id is odd: apply SHA256 hashing to the bill textFinally, check if there are any duplicate on the new column\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "|order_id|product_id|seller_id|      date|num_pieces_sold|       bill_raw_text|\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "|       1|         0|        0|2020-07-10|             26|kyeibuumwlyhuwksx...|\n",
      "|       2|         0|        0|2020-07-08|             13|jfyuoyfkeyqkckwbu...|\n",
      "|       3|         0|        0|2020-07-05|             38|uyjihlzhzcswxcccx...|\n",
      "|       4|         0|        0|2020-07-05|             56|umnxvoqbdzpbwjqmz...|\n",
      "|       5|         0|        0|2020-07-05|             11|zmqexmaawmvdpqhih...|\n",
      "|       6|         0|        0|2020-07-01|             82|lmuhhkpyuoyslwmvX...|\n",
      "|       7|         0|        0|2020-07-04|             15|zoqweontumefxbgvu...|\n",
      "|       8|         0|        0|2020-07-08|             79|sgldfgtcxufasnvsc...|\n",
      "|       9|         0|        0|2020-07-10|             25|jnykelwjjebgkwgmu...|\n",
      "|      10|         0|        0|2020-07-08|              8|yywjfihneygcvfnyl...|\n",
      "|      11|         0|        0|2020-07-01|             10|nxwejyoeznltdhcam...|\n",
      "|      12|         0|        0|2020-07-06|             45|efmymeftivwsfljzt...|\n",
      "|      13|         0|        0|2020-07-10|             63|nxhvtospPhfnkavdy...|\n",
      "|      14|         0|        0|2020-07-03|             22|ypyusdsjzfpfbucnn...|\n",
      "|      15|         0|        0|2020-07-09|             75|ymjvbhaxffyjcwzyn...|\n",
      "|      16|         0|        0|2020-07-10|             83|phbcykkhvqsbkipwa...|\n",
      "|      17|         0|        0|2020-07-04|             54|qgnGqqnjmbqZytoug...|\n",
      "|      18|         0|        0|2020-07-04|             58|ozmllbabrnhebWcex...|\n",
      "|      19|         0|        0|2020-07-07|             33|kbrvXuzgiuinodtkg...|\n",
      "|      20|         0|        0|2020-07-09|             73|jnqjzaigjtqlfwpug...|\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- seller_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- num_pieces_sold: string (nullable = true)\n",
      " |-- bill_raw_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reload()\n",
    "sales_df.show()\n",
    "sales_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_hash(order_id, text):\n",
    "    res = text\n",
    "    if int(order_id) % 2 == 0:\n",
    "        res = hashlib.md5(bytes(res, 'utf-8')).hexdigest()\n",
    "        for c in text:\n",
    "            if c == 'A':\n",
    "                res = hashlib.md5(bytes(res, 'utf-8')).hexdigest()\n",
    "    else:\n",
    "        res = hashlib.sha256(bytes(res, 'utf-8')).hexdigest()\n",
    "    return res\n",
    "        \n",
    "get_hash_udf = F.udf(get_hash, StringType())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'67d25a783609ce62d5456dc297c05dfd'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hash(\"24\", \"jfyuoyfkAAeyqkckwbu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales_df.withColumn(\"hashed_bill\", get_hash_udf(\"order_id\", \"bill_raw_text\")).show()\n",
    "hashed_df = sales_df.withColumn(\"hashed_bill\", get_hash_udf(F.col(\"order_id\"), F.col(\"bill_raw_text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+---------------+--------------------+--------------------+\n",
      "|order_id|product_id|seller_id|      date|num_pieces_sold|       bill_raw_text|         hashed_bill|\n",
      "+--------+----------+---------+----------+---------------+--------------------+--------------------+\n",
      "|       1|         0|        0|2020-07-10|             26|kyeibuumwlyhuwksx...|f6fa2a8be04a4ead6...|\n",
      "|       2|         0|        0|2020-07-08|             13|jfyuoyfkeyqkckwbu...|jfyuoyfkeyqkckwbu...|\n",
      "|       3|         0|        0|2020-07-05|             38|uyjihlzhzcswxcccx...|416376a64cd652e7b...|\n",
      "|       4|         0|        0|2020-07-05|             56|umnxvoqbdzpbwjqmz...|umnxvoqbdzpbwjqmz...|\n",
      "|       5|         0|        0|2020-07-05|             11|zmqexmaawmvdpqhih...|787d361b162a6aa1a...|\n",
      "|       6|         0|        0|2020-07-01|             82|lmuhhkpyuoyslwmvX...|lmuhhkpyuoyslwmvX...|\n",
      "|       7|         0|        0|2020-07-04|             15|zoqweontumefxbgvu...|4540f452a7c4d5049...|\n",
      "|       8|         0|        0|2020-07-08|             79|sgldfgtcxufasnvsc...|sgldfgtcxufasnvsc...|\n",
      "|       9|         0|        0|2020-07-10|             25|jnykelwjjebgkwgmu...|28b93c1c62caa2b97...|\n",
      "|      10|         0|        0|2020-07-08|              8|yywjfihneygcvfnyl...|51d35e22937a5f4f2...|\n",
      "|      11|         0|        0|2020-07-01|             10|nxwejyoeznltdhcam...|000cbc89a752db6c4...|\n",
      "|      12|         0|        0|2020-07-06|             45|efmymeftivwsfljzt...|efmymeftivwsfljzt...|\n",
      "|      13|         0|        0|2020-07-10|             63|nxhvtospPhfnkavdy...|dd67ab7d952be16fa...|\n",
      "|      14|         0|        0|2020-07-03|             22|ypyusdsjzfpfbucnn...|ypyusdsjzfpfbucnn...|\n",
      "|      15|         0|        0|2020-07-09|             75|ymjvbhaxffyjcwzyn...|1ffcc4531e752f9a1...|\n",
      "|      16|         0|        0|2020-07-10|             83|phbcykkhvqsbkipwa...|phbcykkhvqsbkipwa...|\n",
      "|      17|         0|        0|2020-07-04|             54|qgnGqqnjmbqZytoug...|2e93d3b4789a5fb76...|\n",
      "|      18|         0|        0|2020-07-04|             58|ozmllbabrnhebWcex...|ozmllbabrnhebWcex...|\n",
      "|      19|         0|        0|2020-07-07|             33|kbrvXuzgiuinodtkg...|985ddbfaac225a8c2...|\n",
      "|      20|         0|        0|2020-07-09|             73|jnqjzaigjtqlfwpug...|jnqjzaigjtqlfwpug...|\n",
      "+--------+----------+---------+----------+---------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+\n",
      "|hashed_bill|cnt|\n",
      "+-----------+---+\n",
      "+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashed_df.groupby(F.col(\"hashed_bill\")).agg(F.count(\"*\").alias(\"cnt\")).where(F.col(\"cnt\") > 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000040"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashed_df.select(\"hashed_bill\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|count(DISTINCT hashed_bill)|\n",
      "+---------------------------+\n",
      "|                   20000040|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashed_df.agg(F.countDistinct(F.col(\"hashed_bill\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
